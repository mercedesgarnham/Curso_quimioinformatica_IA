{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìò Gu√≠a de ejercicios\n",
    "\n",
    "Pod√©s abrir la [Gu√≠a de ejercicios en Google Colab](https://colab.research.google.com/github/mercedesgarnham/Curso_quimioinformatica_IA/blob/main/notebooks/guia_de_ejercicios.ipynb) para interactuar con la notebook directamente en tu navegador.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Contenidos m√≠nimos recomendados\n",
    "\n",
    "Antes del curso, se recomienda revisar los contenidos de introducci√≥n a Python para poder seguir los ejercicios:  \n",
    "[Introducci√≥n a Python ‚Äì RSG Argentina](https://rsg-argentina.netlify.app/workshops/introduccion_a_python/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducci√≥n a Machine Learning (ML)\n",
    "\n",
    "## ¬øQu√© es Machine Learning?\n",
    "\n",
    "Machine Learning (aprendizaje autom√°tico) es una rama de la inteligencia artificial que permite a las computadoras aprender patrones y tomar decisiones a partir de datos, sin ser expl√≠citamente programadas para cada tarea.\n",
    "\n",
    "En lugar de seguir reglas fijas, un modelo de ML utiliza datos hist√≥ricos para ‚Äúaprender‚Äù y luego hacer predicciones o clasificaciones sobre datos nuevos.\n",
    "\n",
    "## Tipos principales de Machine Learning\n",
    "\n",
    "- **Aprendizaje Supervisado:**  \n",
    "  El modelo aprende a partir de un conjunto de datos etiquetados, donde cada entrada tiene una salida conocida.  \n",
    "  Ejemplos: clasificaci√≥n (activo vs inactivo), regresi√≥n (predecir una propiedad continua).\n",
    "\n",
    "- **Aprendizaje No Supervisado:**  \n",
    "  El modelo encuentra patrones o agrupamientos en datos sin etiquetas.  \n",
    "  Ejemplo: clustering para identificar grupos de mol√©culas similares.\n",
    "\n",
    "- **Aprendizaje por Refuerzo:**  \n",
    "  El modelo aprende a tomar decisiones mediante prueba y error, recibiendo recompensas o penalizaciones.\n",
    "\n",
    "## Componentes clave en ML\n",
    "\n",
    "- **Datos:** el combustible para el aprendizaje.  \n",
    "- **Caracter√≠sticas (features):** representaciones num√©ricas de los datos que el modelo usa para aprender.  \n",
    "- **Modelo:** algoritmo matem√°tico que encuentra patrones en los datos.  \n",
    "- **Funci√≥n objetivo:** m√©trica que el modelo optimiza durante el entrenamiento.  \n",
    "- **Entrenamiento:** proceso de ajustar el modelo a los datos para minimizar errores.  \n",
    "- **Evaluaci√≥n:** medir qu√© tan bien el modelo funciona con datos no vistos.\n",
    "\n",
    "## Aplicaci√≥n en Quimioinform√°tica\n",
    "\n",
    "En quimioinform√°tica, ML se usa para predecir propiedades moleculares, actividad biol√≥gica, toxicidad, entre otros, a partir de la estructura qu√≠mica y datos experimentales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos y An√°lisis de Datos Qu√≠micos\n",
    "\n",
    "## Introducci√≥n: ¬øPor qu√© es importante el tipo de dato?\n",
    "\n",
    "En quimioinform√°tica y modelado molecular, la calidad y tipo de datos que utilicemos es fundamental, ya que influyen directamente en el desempe√±o y confiabilidad de nuestros modelos de inteligencia artificial.\n",
    "\n",
    "No todos los datos son iguales: elegir adecuadamente el tipo de datos y su fuente es clave para obtener resultados robustos y √∫tiles.\n",
    "\n",
    "## Fuentes de datos\n",
    "\n",
    "Podemos obtener datos qu√≠micos y biol√≥gicos de diferentes or√≠genes:\n",
    "\n",
    "- **Datos propios:**  \n",
    "  Resultados experimentales generados en nuestro laboratorio o proyecto. Estos datos suelen ser muy espec√≠ficos y controlados, pero pueden ser limitados en cantidad.\n",
    "\n",
    "- **Datos de publicaciones cient√≠ficas:**  \n",
    "  Informaci√≥n reportada en art√≠culos y trabajos de investigaci√≥n. Es importante validar la calidad y contexto de estos datos antes de usarlos.\n",
    "\n",
    "- **Bases de datos p√∫blicas:**  \n",
    "  Repositorios como ChEMBL, PubChem que almacenan miles o millones de compuestos con sus propiedades y resultados de bioensayos.\n",
    "\n",
    "## Tipos de datos y su impacto\n",
    "\n",
    "Los datos qu√≠micos y biol√≥gicos pueden venir en diferentes formatos y contextos, por ejemplo:\n",
    "\n",
    "- **Estructuras moleculares:**  \n",
    "  Generalmente representadas como SMILES o InChI, son la base para cualquier an√°lisis y modelado.\n",
    "\n",
    "- **Bioactividad:**  \n",
    "  Indican si una mol√©cula es activa o inactiva frente a un target o ensayos espec√≠ficos. Esta informaci√≥n puede variar seg√∫n el tipo de bioensayo utilizado.\n",
    "\n",
    "- **Tipos de bioensayos:**  \n",
    "  Cada tipo de ensayo mide diferentes aspectos biol√≥gicos o farmacol√≥gicos, como:\n",
    "\n",
    "  - Ensayos de inhibici√≥n enzim√°tica (p.ej. IC50, Ki)  \n",
    "  - Ensayos celulares funcionales  \n",
    "  - Ensayos fenot√≠picos  \n",
    "  - Ensayos toxicol√≥gicos\n",
    "\n",
    "La selecci√≥n del tipo de bioensayo afecta la definici√≥n de ‚Äúactividad‚Äù y por lo tanto el etiquetado de los datos para el entrenamiento del modelo.\n",
    "\n",
    "## Importancia de la correcta selecci√≥n y curaci√≥n de datos\n",
    "\n",
    "- **Consistencia:**  \n",
    "  Es clave que los datos provengan de ensayos comparables para evitar introducir ruido o sesgo.\n",
    "\n",
    "- **Cantidad vs calidad:**  \n",
    "  A veces hay que balancear tener muchos datos con tener datos confiables y bien caracterizados.\n",
    "\n",
    "- **Preprocesamiento y validaci√≥n:**  \n",
    "  Limpieza, filtrado y normalizaci√≥n son pasos imprescindibles para preparar los datos antes de modelar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplos de Uso de Machine Learning en Quimioinform√°tica con Referencias\n",
    "\n",
    "Machine Learning tiene m√∫ltiples aplicaciones en quimioinform√°tica. \n",
    "\n",
    "## Material de consulta: \n",
    "\n",
    "- [Practical Cheminformatics](https://patwalters.github.io/)\n",
    "- [A Deep Learning Approach to Antibiotic Discovery](https://www.sciencedirect.com/science/article/pii/S0092867420301021)\n",
    "- [AI in Drug Discovery](https://link.springer.com/book/10.1007/978-3-031-72381-0)\n",
    "\n",
    "\n",
    "Empecemos a trabajar!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas scikit-learn rdkit matplotlib seaborn xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, MACCSkeys, rdFingerprintGenerator, rdMolDescriptors, Descriptors\n",
    "from rdkit.ML.Descriptors.MoleculeDescriptors import MolecularDescriptorCalculator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/mercedesgarnham/Curso_quimioinformatica_IA/refs/heads/main/data/AID_1885.csv\"\n",
    "df = pd.read_csv(url, sep =\",\")\n",
    "\n",
    "df = df[['PUBCHEM_ACTIVITY_OUTCOME','PUBCHEM_EXT_DATASOURCE_SMILES']]\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n r√°pida\n",
    "plt.figure(figsize=(6,4))\n",
    "df['PUBCHEM_ACTIVITY_OUTCOME'].value_counts().plot(kind='bar', color=['skyblue', 'salmon', \"grey\"])\n",
    "plt.title('Distribuci√≥n de actividad')\n",
    "plt.xlabel('Actividad')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar solo Active e Inactive\n",
    "df_filtered = df[df['PUBCHEM_ACTIVITY_OUTCOME'].isin(['Active', 'Inactive'])].copy()\n",
    "df_filtered.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar SMILES y crear objetos Mol (RDKit)\n",
    "def mol_from_smiles(smiles):\n",
    "    try:\n",
    "        return Chem.MolFromSmiles(smiles)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df_filtered['mol'] = df_filtered['PUBCHEM_EXT_DATASOURCE_SMILES'].apply(mol_from_smiles)\n",
    "df_filtered = df_filtered[df_filtered['mol'].notnull()].copy()\n",
    "df_filtered.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribuci√≥n de datos\n",
    "\n",
    "## Uso de dataset completo vs. dataset balanceado en modelos de Machine Learning\n",
    "\n",
    "Cuando entrenamos un modelo de Machine Learning sobre un dataset **desbalanceado**, como suele ocurrir con compuestos activos e inactivos, el modelo puede verse sesgado hacia la **clase mayoritaria**. Esto significa que:\n",
    "\n",
    "- Puede predecir correctamente la clase mayoritaria la mayor parte del tiempo.\n",
    "- Puede ignorar o predecir mal la clase minoritaria (por ejemplo, los compuestos activos si son pocos).\n",
    "- Las m√©tricas tradicionales como **accuracy** pueden ser enga√±osas, porque un modelo que siempre predice la clase mayoritaria puede tener alta precisi√≥n sin realmente aprender nada √∫til.\n",
    "\n",
    "Al usar un **dataset balanceado**, mediante muestreo aleatorio o t√©cnicas como SMOTE, conseguimos:\n",
    "\n",
    "- Que el modelo tenga **igual exposici√≥n a ambas clases**, aprendiendo patrones de manera m√°s justa.\n",
    "- Mejores m√©tricas de evaluaci√≥n para ambas clases, como **recall, precision y F1-score**.\n",
    "- Menor riesgo de sobreajuste hacia la clase mayoritaria.\n",
    "\n",
    "‚ö†Ô∏è Nota: Balancear puede implicar **perder informaci√≥n de la clase mayoritaria** si se hace muestreo aleatorio, pero es un compromiso necesario cuando el desbalance es fuerte.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impacto del desbalance de datos en Drug Discovery\n",
    "\n",
    "En Drug Discovery, los datasets de bioactividad suelen estar **muy desbalanceados**: la mayor√≠a de los compuestos son **inactivos** frente a un target, y solo unos pocos son **activos**. Esto tiene varias implicancias para Machine Learning:\n",
    "\n",
    "### Problemas al usar todos los datos\n",
    "- El modelo tiende a predecir la clase mayoritaria (**inactivos**) casi siempre.  \n",
    "- M√©tricas como **accuracy** pueden ser enga√±osas, mostrando buen desempe√±o aunque falle en detectar activos.  \n",
    "- Los **falsos negativos** (no detectar un compuesto activo) son cr√≠ticos, porque se pierden candidatos potenciales de f√°rmaco.\n",
    "\n",
    "### Beneficios de usar un dataset balanceado\n",
    "- Igual exposici√≥n a ambas clases, ayudando al modelo a **aprender patrones de activos**.  \n",
    "- Mejora de m√©tricas relevantes como **recall, precision y F1-score** para la clase minoritaria.  \n",
    "- Menor sesgo hacia la clase mayoritaria, permitiendo identificar compuestos activos prometedores.\n",
    "\n",
    "### Estrategias comunes\n",
    "- **Muestreo aleatorio** de inactivos o **sobremuestreo** de activos (SMOTE).  \n",
    "- **Ponderar la clase minoritaria** en la funci√≥n de p√©rdida del modelo.  \n",
    "- Evaluar con m√©tricas **sensible a desbalance** (recall, F1-score, ROC-AUC) en lugar de solo accuracy.\n",
    "\n",
    "> ‚ö†Ô∏è En resumen: balancear o ponderar datos es clave en drug discovery para que los modelos ML detecten compuestos activos, que son los m√°s valiosos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag para decidir si usar dataset balanceado o completo\n",
    "usar_balanceado = True  # Cambiar a False para usar todos los datos (sampleado)\n",
    "\n",
    "# N√∫mero de activos para el dataset balanceado\n",
    "actives = df_filtered[df_filtered['PUBCHEM_ACTIVITY_OUTCOME'] == 'Active']\n",
    "n_actives = len(actives)\n",
    "\n",
    "if usar_balanceado:\n",
    "    # Balancear dataset con muestreo aleatorio de inactivos para igualar cantidad de activos\n",
    "    inactives = df_filtered[df_filtered['PUBCHEM_ACTIVITY_OUTCOME'] == 'Inactive']\n",
    "    inactives_sampled = inactives.sample(n=n_actives, random_state=42)  # Semilla para reproducibilidad\n",
    "\n",
    "    df_final = pd.concat([actives, inactives_sampled]).reset_index(drop=True)\n",
    "\n",
    "    print(f\"Cantidad de activos: {len(actives)}\")\n",
    "    print(f\"Cantidad de inactivos muestreados: {len(inactives_sampled)}\")\n",
    "    print(f\"Tama√±o total dataset balanceado: {len(df_final)}\")\n",
    "else:\n",
    "    # Usar todos los datos pero tomar un sample del mismo tama√±o que el balanceado\n",
    "    df_sampled = df_filtered.sample(n=n_actives*2, random_state=42)  # mismo tama√±o que balanceado\n",
    "    df_final = df_sampled.reset_index(drop=True)\n",
    "\n",
    "    print(f\"Tama√±o total dataset sampleado: {len(df_final)}\")\n",
    "    print(df_final['PUBCHEM_ACTIVITY_OUTCOME'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular propiedades fisicoqu√≠micas b√°sicas\n",
    "def calc_properties(mol):\n",
    "    return {\n",
    "        'MolWt': Descriptors.MolWt(mol),\n",
    "        'LogP': Descriptors.MolLogP(mol),\n",
    "        'NumHDonors': Descriptors.NumHDonors(mol),\n",
    "        'NumHAcceptors': Descriptors.NumHAcceptors(mol),\n",
    "        'TPSA': Descriptors.TPSA(mol)\n",
    "    }\n",
    "\n",
    "props = df_final['mol'].apply(calc_properties)\n",
    "props_df = pd.DataFrame(list(props))\n",
    "df_final = pd.concat([df_final, props_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribuci√≥n de clases balanceadas\n",
    "plt.figure(figsize=(6,4))\n",
    "df_final['PUBCHEM_ACTIVITY_OUTCOME'].value_counts().plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "plt.title('Distribuci√≥n de clases balanceadas Active vs Inactive')\n",
    "plt.xlabel('Actividad')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de propiedades por clase balanceadas\n",
    "plt.figure(figsize=(12,8))\n",
    "for i, prop in enumerate(['MolWt', 'LogP', 'NumHDonors', 'NumHAcceptors', 'TPSA']):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    sns.boxplot(x='PUBCHEM_ACTIVITY_OUTCOME', y=prop, data=df_final)\n",
    "    plt.title(f'Distribuci√≥n de {prop} por clase')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representaci√≥n y Featurizaci√≥n de Mol√©culas\n",
    "\n",
    "## ¬øPor qu√© es importante la representaci√≥n de las mol√©culas?\n",
    "\n",
    "Una vez que hemos obtenido y curado nuestros datos qu√≠micos y bioactivos, el siguiente paso cr√≠tico es c√≥mo representamos esas mol√©culas para que los algoritmos de Machine Learning puedan entenderlas y trabajar con ellas.\n",
    "\n",
    "La representaci√≥n o **featurizaci√≥n** convierte la estructura qu√≠mica en vectores num√©ricos o caracter√≠sticas que describen aspectos relevantes de las mol√©culas.\n",
    "\n",
    "## Tipos comunes de featurizaci√≥n\n",
    "\n",
    "- **Fingerprints (huellas moleculares):**  \n",
    "  Representaciones binarias o num√©ricas que codifican la presencia o ausencia de subestructuras qu√≠micas, patrones o fragmentos.  \n",
    "  Ejemplos:  \n",
    "  - *Morgan fingerprints* (circular)  \n",
    "  - *MACCS keys*  \n",
    "  - *Topological fingerprints*\n",
    "\n",
    "- **Descriptores fisicoqu√≠micos:**  \n",
    "  Valores num√©ricos que representan propiedades moleculares calculadas o experimentales, como:  \n",
    "  - Peso molecular  \n",
    "  - LogP (lipofilicidad)  \n",
    "  - N√∫mero de √°tomos de hidr√≥geno donadores y aceptores  \n",
    "  - N√∫mero de rotaciones libres  \n",
    "  - Polaridad, etc.\n",
    "\n",
    "- **Representaciones basadas en gr√°ficos:**  \n",
    "  Modelos m√°s complejos que consideran la estructura molecular como un grafo (nodos y enlaces) para modelos de Deep Learning.\n",
    "\n",
    "## ¬øC√≥mo elegir la mejor forma de featurizar?\n",
    "\n",
    "- Depende del **tipo de modelo** que usar√°s: algunos modelos funcionan mejor con fingerprints, otros con descriptores, y los modelos de deep learning pueden usar representaciones m√°s complejas.  \n",
    "- Depende de la **cantidad y calidad de datos**: con pocos datos, las representaciones simples pueden ser m√°s robustas.  \n",
    "- Depende del **problema y la tarea espec√≠fica**: por ejemplo, predicci√≥n de actividad biol√≥gica, propiedades fisicoqu√≠micas, etc.  \n",
    "- La **interpretabilidad** tambi√©n es clave: algunos descriptores permiten entender mejor qu√© propiedades influyen en la predicci√≥n.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fingerprints utilizados en el an√°lisis de mol√©culas\n",
    "\n",
    "En nuestro trabajo usamos los siguientes fingerprints, que son representaciones binarias o vectoriales de las mol√©culas:\n",
    "\n",
    "| Fingerprint | Tipo de informaci√≥n | Qu√© captura | Uso t√≠pico |\n",
    "|------------|-------------------|------------|------------|\n",
    "| **fp_morgan_array** | Circular / ECFP | Entorno local de √°tomos (subestructuras) hasta un radio determinado | QSAR, similitud molecular, b√∫squeda de compuestos activos |\n",
    "| **fp_rdkit_array** | Topol√≥gico lineal | Caminos lineales de √°tomos dentro de la mol√©cula | Comparaci√≥n r√°pida de mol√©culas, clustering |\n",
    "| **fp_maccs_array** | MACCS keys (166 bits) | Presencia o ausencia de subestructuras predefinidas | Filtros qu√≠micos, b√∫squeda r√°pida, comparaci√≥n b√°sica |\n",
    "| **fp_topological_torsion_array** | Torsiones topol√≥gicas | Secuencias de 4 √°tomos conectados (torsiones) | QSAR, relaci√≥n con actividad biol√≥gica |\n",
    "| **fp_atom_pair_array** | Pares de √°tomos + distancia topol√≥gica | Relaci√≥n global entre pares de √°tomos y distancia entre ellos | Similitud global, mol√©culas grandes, detecci√≥n de patrones espaciales |\n",
    "\n",
    "> ‚ö° **Nota:** Cada fingerprint captura diferentes aspectos de la qu√≠mica de las mol√©culas. La elecci√≥n del fingerprint puede impactar el rendimiento del modelo de Machine Learning y su capacidad de detectar compuestos activos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para convertir fingerprint a numpy array\n",
    "def fp_to_array(fp):\n",
    "    arr = np.zeros((fp.GetNumBits(),), dtype=int)\n",
    "    Chem.DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    return arr\n",
    "\n",
    "# Morgan Fingerprints (radius=2, 1024 bits)\n",
    "df_final['fp_morgan'] = df_final['mol'].apply(lambda m: AllChem.GetMorganFingerprintAsBitVect(m, radius=2, nBits=1024))\n",
    "df_final['fp_morgan_array'] = df_final['fp_morgan'].apply(fp_to_array)\n",
    "\n",
    "# RDKit Fingerprints (default params)\n",
    "df_final['fp_rdkit'] = df_final['mol'].apply(lambda m: Chem.RDKFingerprint(m))\n",
    "df_final['fp_rdkit_array'] = df_final['fp_rdkit'].apply(fp_to_array)\n",
    "\n",
    "# MACCS Keys (166 bits)\n",
    "df_final['fp_maccs'] = df_final['mol'].apply(lambda m: MACCSkeys.GenMACCSKeys(m))\n",
    "df_final['fp_maccs_array'] = df_final['fp_maccs'].apply(fp_to_array)\n",
    "\n",
    "# Topological Torsion Fingerprints\n",
    "topo_generator = rdFingerprintGenerator.GetTopologicalTorsionGenerator()\n",
    "df_final['fp_topological_torsion'] = df_final['mol'].apply(lambda m: topo_generator.GetFingerprint(m))\n",
    "df_final['fp_topological_torsion_array'] = df_final['fp_topological_torsion'].apply(fp_to_array)\n",
    "\n",
    "# Atom Pair Fingerprints\n",
    "atompair_generator = rdFingerprintGenerator.GetAtomPairGenerator()\n",
    "df_final['fp_atom_pair'] = df_final['mol'].apply(lambda m: atompair_generator.GetFingerprint(m))\n",
    "df_final['fp_atom_pair_array'] = df_final['fp_atom_pair'].apply(fp_to_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceptos clave de Machine Learning\n",
    "\n",
    "Machine Learning (ML) es un conjunto de t√©cnicas que permite a las computadoras **aprender patrones a partir de datos** y hacer predicciones o clasificaciones sobre datos nuevos.  \n",
    "\n",
    "### Elementos fundamentales\n",
    "\n",
    "1. **Datos y features**  \n",
    "   - Los modelos aprenden a partir de un conjunto de datos representados mediante **features** (variables predictoras).  \n",
    "   - La calidad, relevancia y cantidad de features son cruciales para el rendimiento del modelo.  \n",
    "\n",
    "2. **Etiquetas / targets**  \n",
    "   - En problemas de clasificaci√≥n, cada ejemplo tiene una **clase o categor√≠a**.  \n",
    "   - En problemas de regresi√≥n, cada ejemplo tiene un **valor num√©rico continuo** que el modelo intenta predecir.  \n",
    "\n",
    "3. **Entrenamiento y evaluaci√≥n**  \n",
    "   - Los datos se dividen en **conjunto de entrenamiento** y **conjunto de prueba**.  \n",
    "   - El entrenamiento consiste en ajustar los par√°metros del modelo para **minimizar el error** sobre los datos conocidos.  \n",
    "   - La evaluaci√≥n se hace sobre datos no vistos para medir **generalizaci√≥n**, usando m√©tricas como accuracy, precision, recall, f1-score, AUC, etc.\n",
    "\n",
    "4. **Hiperpar√°metros**  \n",
    "   - Son par√°metros que **no se aprenden del entrenamiento**, sino que se fijan antes o se optimizan mediante validaci√≥n cruzada.  \n",
    "   - Ejemplos: n√∫mero de √°rboles en Random Forest, `C` y `gamma` en SVM, `learning_rate` y `max_depth` en XGBoost.  \n",
    "\n",
    "5. **Balanceo de clases**  \n",
    "   - En datasets desbalanceados, donde algunas clases tienen muchos m√°s ejemplos que otras, es recomendable usar t√©cnicas como **submuestreo, sobremuestreo o ponderaci√≥n de clases** para mejorar el rendimiento y la interpretabilidad.\n",
    "\n",
    "6. **Selecci√≥n de modelo**  \n",
    "   - La elecci√≥n del modelo depende del tipo de problema, tama√±o del dataset, n√∫mero de features, linealidad de las relaciones y la necesidad de interpretabilidad.  \n",
    "   - Es recomendable **comparar varios modelos** y sus m√©tricas de rendimiento para decidir cu√°l es el m√°s adecuado.\n",
    "\n",
    "> üîπ Nota: En quimioinform√°tica y drug discovery, la selecci√≥n de fingerprints, el balance de datos y la interpretaci√≥n de la importancia de features son **cruciales** para obtener resultados confiables y √∫tiles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elecci√≥n del Modelo de Inteligencia Artificial\n",
    "\n",
    "## ¬øPor qu√© es importante elegir el modelo correcto?\n",
    "\n",
    "La selecci√≥n del modelo de Machine Learning o Deep Learning adecuado es clave para obtener predicciones precisas y confiables en tareas de quimioinform√°tica. Diferentes modelos tienen ventajas y limitaciones seg√∫n el tipo de datos, tama√±o del dataset y complejidad del problema.\n",
    "\n",
    "## Factores a considerar para elegir el modelo\n",
    "\n",
    "- **Cantidad de datos disponibles:**  \n",
    "  - Con grandes vol√∫menes de datos, los modelos de Deep Learning (como redes neuronales convolucionales o grafos neuronales) pueden capturar patrones complejos.  \n",
    "  - Con pocos datos, modelos tradicionales como Random Forest, Support Vector Machines o regresi√≥n log√≠stica suelen ser m√°s robustos y menos propensos al sobreajuste.\n",
    "\n",
    "- **Tipo y complejidad de las caracter√≠sticas:**  \n",
    "  - Para descriptores simples o fingerprints, modelos cl√°sicos funcionan bien.  \n",
    "  - Para representaciones basadas en grafos o secuencias, modelos basados en Deep Learning pueden ser m√°s adecuados.\n",
    "\n",
    "- **Interpretabilidad:**  \n",
    "  - Modelos como Random Forest o regresiones permiten interpretar qu√© variables influyen en la predicci√≥n.  \n",
    "  - Redes neuronales profundas suelen ser ‚Äúcajas negras‚Äù y requieren t√©cnicas adicionales para interpretarlas.\n",
    "\n",
    "- **Tiempo y recursos computacionales:**  \n",
    "  - Modelos simples entrenan y predicen r√°pidamente.  \n",
    "  - Modelos complejos necesitan m√°s poder de c√≥mputo y tiempo de entrenamiento.\n",
    "\n",
    "## Ejemplos comunes de modelos para quimioinform√°tica\n",
    "\n",
    "- **Random Forest:** Popular para clasificaci√≥n y regresi√≥n, f√°cil de usar y robusto.  \n",
    "- **Support Vector Machines (SVM):** Bueno para datasets medianos con alta dimensionalidad.  \n",
    "- **Redes Neuronales Artificiales (ANN):** Flexibles, usadas con fingerprints o descriptores.  \n",
    "- **Redes Neuronales Convolucionales (CNN):** Para datos con estructura espacial, como im√°genes o secuencias.  \n",
    "- **Modelos basados en Grafos:** Para representar directamente la estructura molecular.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M√©tricas de evaluaci√≥n en clasificaci√≥n\n",
    "\n",
    "Cuando trabajamos con modelos de clasificaci√≥n, es importante evaluar su rendimiento usando m√©tricas que reflejen **exactitud, balance y capacidad de predicci√≥n**.  \n",
    "\n",
    "| M√©trica | Qu√© mide | F√≥rmula b√°sica | Interpretaci√≥n |\n",
    "|---------|----------|----------------|----------------|\n",
    "| **Accuracy** | Porcentaje de predicciones correctas | (TP + TN) / (TP + TN + FP + FN) | Ideal si las clases est√°n balanceadas; puede ser enga√±osa en datasets desbalanceados. |\n",
    "| **Precision (o Positive Predictive Value)** | Qu√© proporci√≥n de predicciones positivas son correctas | TP / (TP + FP) | Alta precision indica pocas falsas alarmas. |\n",
    "| **Recall (o Sensitivity / True Positive Rate)** | Qu√© proporci√≥n de positivos reales fueron correctamente identificados | TP / (TP + FN) | Alto recall indica que el modelo detecta la mayor√≠a de positivos. |\n",
    "| **F1-score** | Media arm√≥nica de precision y recall | 2 * (Precision * Recall) / (Precision + Recall) | √ötil cuando necesitamos balancear precision y recall; importante en datasets desbalanceados. |\n",
    "| **Specificity (True Negative Rate)** | Qu√© proporci√≥n de negativos reales fueron correctamente identificados | TN / (TN + FP) | Complemento del recall para la clase negativa. |\n",
    "| **AUC-ROC** | √Årea bajo la curva ROC (recall vs. false positive rate) | Calculada a partir de probabilidades | Indica la capacidad de separar clases; 1 = perfecto, 0.5 = aleatorio. |\n",
    "| **Confusion Matrix** | Matriz que muestra TP, TN, FP y FN | - | Permite ver errores por clase y ayuda a interpretar precision y recall. |\n",
    "\n",
    "## Curva ROC (Receiver Operating Characteristic)\n",
    "\n",
    "La **curva ROC** es una herramienta para evaluar el rendimiento de un modelo de clasificaci√≥n, especialmente cuando se predicen probabilidades en lugar de clases directas.\n",
    "\n",
    "### Concepto\n",
    "- La curva muestra **la relaci√≥n entre el True Positive Rate (Recall)** y **el False Positive Rate (1 - Specificity)** para distintos **umbrales de decisi√≥n**.\n",
    "- Cada punto de la curva corresponde a un umbral diferente, es decir, a un valor de probabilidad a partir del cual clasificamos un ejemplo como positivo.\n",
    "\n",
    "### Ejes de la curva\n",
    "- **Eje X (FPR)**: False Positive Rate = FP / (FP + TN)  \n",
    "- **Eje Y (TPR)**: True Positive Rate (Recall) = TP / (TP + FN)\n",
    "\n",
    "### √Årea bajo la curva (AUC)\n",
    "- El √°rea bajo la curva (AUC) resume el desempe√±o del modelo en un solo n√∫mero.  \n",
    "  - AUC = 1 ‚Üí modelo perfecto, separa todas las clases sin errores.  \n",
    "  - AUC = 0.5 ‚Üí modelo aleatorio, sin poder de discriminaci√≥n.  \n",
    "- Cuanto m√°s se acerque la curva a la esquina superior izquierda, mejor es el modelo.\n",
    "\n",
    "### Interpretaci√≥n pr√°ctica\n",
    "- Permite **comparar modelos independientemente del umbral elegido**.  \n",
    "- Muy √∫til en **datasets desbalanceados**, como ocurre en drug discovery, donde los positivos son raros y elegir el umbral adecuado es cr√≠tico.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para plotear matriz de confusi√≥n y ROC para un modelo dado\n",
    "def plot_model_performance(model, X_test, y_test, model_name):\n",
    "    # Matriz de confusi√≥n\n",
    "    ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)\n",
    "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Curva ROC\n",
    "    RocCurveDisplay.from_estimator(model, X_test, y_test)\n",
    "    plt.title(f\"ROC Curve - {model_name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir actividad a 0/1\n",
    "df_final['activity'] = df_final['PUBCHEM_ACTIVITY_OUTCOME'].str.lower().map({'active': 1, 'inactive': 0})\n",
    "\n",
    "# Lista de fingerprints disponibles\n",
    "fps_disponibles = ['fp_morgan_array', 'fp_rdkit_array', 'fp_maccs_array','fp_topological_torsion_array', 'fp_atom_pair_array']\n",
    "\n",
    "# Elegir fingerprint\n",
    "fp_elegido = fps_disponibles[0]  # Cambiar el √≠ndice o nombre seg√∫n la elecci√≥n\n",
    "\n",
    "# Verificar si el fingerprint elegido est√° en la lista\n",
    "if fp_elegido in fps_disponibles:\n",
    "    X = np.stack(df_final[fp_elegido].values)\n",
    "    y = df_final['activity'].values  \n",
    "\n",
    "    # Dividir en train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(f\"Usando fingerprint: {fp_elegido}\")\n",
    "    print(f\"Forma de X: {X.shape}, forma de y: {y.shape}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Error: el fingerprint elegido '{fp_elegido}' no est√° en la lista. Elegir uno de: {fps_disponibles}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest: funcionamiento y caracter√≠sticas\n",
    "\n",
    "**Random Forest** es un algoritmo de ensamble basado en √°rboles de decisi√≥n:\n",
    "\n",
    "1. **Bosque de √°rboles**  \n",
    "   - Construye m√∫ltiples √°rboles de decisi√≥n sobre **submuestras aleatorias de los datos**.  \n",
    "   - Cada √°rbol se entrena usando un **subconjunto aleatorio de features**, lo que reduce el sobreajuste y aumenta la generalizaci√≥n.\n",
    "\n",
    "2. **Predicci√≥n y votaci√≥n**  \n",
    "   - Cada √°rbol predice de manera independiente.  \n",
    "   - La predicci√≥n final se obtiene mediante **votaci√≥n mayoritaria** (clasificaci√≥n) o promedio (regresi√≥n).\n",
    "\n",
    "3. **Importancia de features**  \n",
    "   - Random Forest permite evaluar cu√°nto contribuye cada feature a la predicci√≥n final, √∫til para interpretar modelos de QSAR o qu√≠mica computacional.\n",
    "\n",
    "4. **Hiperpar√°metros principales**  \n",
    "   - `n_estimators`: n√∫mero de √°rboles en el bosque.  \n",
    "   - `max_depth`: profundidad m√°xima de cada √°rbol.  \n",
    "   - `min_samples_split`: m√≠nimo de muestras requeridas para dividir un nodo.  \n",
    "   - `min_samples_leaf`: m√≠nimo de muestras que debe tener una hoja.  \n",
    "   - `max_features`: n√∫mero de features consideradas para la mejor divisi√≥n en cada nodo.  \n",
    "   - `bootstrap`: si se utilizan muestras con reemplazo para construir cada √°rbol.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "plot_model_performance(rf, X_test, y_test, \"Random Forest\")\n",
    "\n",
    "# Importancia de features Random Forest\n",
    "importances_rf = rf.feature_importances_\n",
    "indices_rf = importances_rf.argsort()[::-1]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"Feature Importances - Random Forest\")\n",
    "plt.bar(range(len(importances_rf)), importances_rf[indices_rf], align='center')\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost: funcionamiento y caracter√≠sticas\n",
    "\n",
    "**XGBoost** (Extreme Gradient Boosting) es un algoritmo de ensamble basado en **boosting de √°rboles de decisi√≥n**:\n",
    "\n",
    "1. **Boosting de √°rboles**  \n",
    "   - Construye √°rboles secuencialesmente, donde **cada nuevo √°rbol intenta corregir los errores del anterior**.  \n",
    "   - Esto permite que el modelo aprenda patrones complejos y reduzca el sesgo.\n",
    "\n",
    "2. **Predicci√≥n acumulativa**  \n",
    "   - Cada √°rbol aporta una predicci√≥n que se suma a las predicciones anteriores.  \n",
    "   - La salida final es la combinaci√≥n ponderada de todos los √°rboles.\n",
    "\n",
    "3. **Hiperpar√°metros principales**  \n",
    "   - `n_estimators`: n√∫mero total de √°rboles.  \n",
    "   - `max_depth`: profundidad m√°xima de cada √°rbol.  \n",
    "   - `learning_rate` (eta): cu√°nto contribuye cada √°rbol a la predicci√≥n final.  \n",
    "   - `subsample`: fracci√≥n de muestras usadas para construir cada √°rbol (reduce sobreajuste).  \n",
    "   - `colsample_bytree`: fracci√≥n de features consideradas para cada √°rbol.  \n",
    "   - `gamma`: penalizaci√≥n m√≠nima de reducci√≥n de p√©rdida para realizar una partici√≥n adicional.  \n",
    "   - `min_child_weight`: suma m√≠nima de pesos de instancias en un nodo hoja (controla sobreajuste).  \n",
    "   - `reg_alpha` y `reg_lambda`: regularizaci√≥n L1 y L2 sobre los pesos de los √°rboles.\n",
    "\n",
    "4. **Interpretaci√≥n y uso**  \n",
    "   - XGBoost es muy potente en datasets **con muchas features y relaciones no lineales**, como fingerprints qu√≠micas.  \n",
    "   - Permite controlar sobreajuste mediante par√°metros de regularizaci√≥n y muestreo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "plot_model_performance(xgb_model, X_test, y_test, \"XGBoost\")\n",
    "\n",
    "# Importancia de features XGBoost\n",
    "importances_xgb = xgb_model.feature_importances_\n",
    "indices_xgb = importances_xgb.argsort()[::-1]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"Feature Importances - XGBoost\")\n",
    "plt.bar(range(len(importances_xgb)), importances_xgb[indices_xgb], align='center')\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM (Support Vector Machine): funcionamiento y caracter√≠sticas\n",
    "\n",
    "**Support Vector Machine (SVM)** es un algoritmo de clasificaci√≥n que encuentra el **hiperplano que mejor separa las clases** en el espacio de features:\n",
    "\n",
    "1. **Separaci√≥n de clases**  \n",
    "   - SVM busca maximizar el **margen** entre las clases, es decir, la distancia entre el hiperplano y los puntos m√°s cercanos de cada clase (support vectors).  \n",
    "   - Es especialmente √∫til cuando las clases no se superponen demasiado y el espacio de features es de alta dimensi√≥n.\n",
    "\n",
    "2. **Kernel trick**  \n",
    "   - Permite transformar los datos a un espacio de mayor dimensi√≥n donde puedan ser linealmente separables.  \n",
    "   - Kernels comunes: `linear`, `rbf` (radial basis function), `poly` (polinomial).\n",
    "\n",
    "3. **Hiperpar√°metros principales**  \n",
    "   - `C`: controla la penalizaci√≥n por errores de clasificaci√≥n. Valores grandes buscan **margen m√°s estricto**, valores peque√±os permiten m√°s errores.  \n",
    "   - `kernel`: tipo de funci√≥n de kernel (`linear`, `rbf`, `poly`, `sigmoid`).  \n",
    "   - `gamma`: define la influencia de un solo punto de entrenamiento en kernels como `rbf` o `poly`.  \n",
    "   - `degree`: grado del polinomio (solo para kernel `poly`).  \n",
    "   - `coef0`: t√©rmino independiente en kernels `poly` o `sigmoid`.\n",
    "\n",
    "4. **Interpretaci√≥n y uso**  \n",
    "   - SVM es muy efectivo en datasets con **muchas features**, como fingerprints qu√≠micas, donde las clases son separables en espacios de alta dimensi√≥n.  \n",
    "   - Su principal ventaja es encontrar fronteras de decisi√≥n muy precisas, pero puede ser sensible a la elecci√≥n de hiperpar√°metros y al tama√±o del dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM (con kernel lineal)\n",
    "svm = SVC(kernel='linear', probability=True, random_state=42) #Este paso demora unos minutos! Tener paciencia!\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "plot_model_performance(svm, X_test, y_test, \"SVM\")\n",
    "\n",
    "# Nota: SVM no tiene importancia de features directa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo en grupo\n",
    "Ahora vamos a dividirnos en grupos y comprar las diferentes features con los diferentes modelos:\n",
    "\n",
    "| #  | Fingerprint                  | Dataset    | Modelo        |\n",
    "| -- | ---------------------------- | ---------- | ------------- |\n",
    "| 1  | fp_morgan_array              | Balanceado | SVM           |\n",
    "| 2  | fp_morgan_array              | Balanceado | Random Forest |\n",
    "| 3  | fp_morgan_array              | Balanceado | XGBoost       |\n",
    "| 4  | fp_morgan_array              | Completo   | SVM           |\n",
    "| 5  | fp_morgan_array              | Completo   | Random Forest |\n",
    "| 6  | fp_morgan_array              | Completo   | XGBoost       |\n",
    "| 7  | fp_rdkit_array               | Balanceado | SVM           |\n",
    "| 8  | fp_rdkit_array               | Balanceado | Random Forest |\n",
    "| 9  | fp_rdkit_array               | Balanceado | XGBoost       |\n",
    "| 10 | fp_rdkit_array               | Completo   | SVM           |\n",
    "| 11 | fp_rdkit_array               | Completo   | Random Forest |\n",
    "| 12 | fp_rdkit_array               | Completo   | XGBoost       |\n",
    "| 13 | fp_maccs_array               | Balanceado | SVM           |\n",
    "| 14 | fp_maccs_array               | Balanceado | Random Forest |\n",
    "| 15 | fp_maccs_array               | Balanceado | XGBoost       |\n",
    "| 16 | fp_maccs_array               | Completo   | SVM           |\n",
    "| 17 | fp_maccs_array               | Completo   | Random Forest |\n",
    "| 18 | fp_maccs_array               | Completo   | XGBoost       |\n",
    "| 19 | fp_topological_torsion_array | Balanceado | SVM           |\n",
    "| 20 | fp_topological_torsion_array | Balanceado | Random Forest |\n",
    "| 21 | fp_topological_torsion_array | Balanceado | XGBoost       |\n",
    "| 22 | fp_topological_torsion_array | Completo   | SVM           |\n",
    "| 23 | fp_topological_torsion_array | Completo   | Random Forest |\n",
    "| 24 | fp_topological_torsion_array | Completo   | XGBoost       |\n",
    "| 25 | fp_atom_pair_array           | Balanceado | SVM           |\n",
    "| 26 | fp_atom_pair_array           | Balanceado | Random Forest |\n",
    "| 27 | fp_atom_pair_array           | Balanceado | XGBoost       |\n",
    "| 28 | fp_atom_pair_array           | Completo   | SVM           |\n",
    "| 29 | fp_atom_pair_array           | Completo   | Random Forest |\n",
    "| 30 | fp_atom_pair_array           | Completo   | XGBoost       |\n",
    "\n",
    "Incorporar los resultados a la [diapositiva](https://docs.google.com/presentation/d/1CCIcWUqV1pHKC2IPCLeP35USmgV1jcws92VtsUkTXEY/edit?usp=sharing) y completar la tabla final para comparar los resultaods obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consideraciones Generales y C√≥mo Colaborar\n",
    "\n",
    "## Aspectos clave a tener en cuenta durante el desarrollo\n",
    "\n",
    "- **Desbalance de datos:**  \n",
    "  En problemas de clasificaci√≥n de actividad biol√≥gica, es com√∫n que haya muchos m√°s compuestos inactivos que activos (o viceversa). Este desbalance puede afectar negativamente el desempe√±o del modelo y provocar sesgos.  \n",
    "  **Estrategias:** usar t√©cnicas de balanceo como oversampling (SMOTE), undersampling, o ajustar m√©tricas y umbrales.\n",
    "\n",
    "- **Similitud intra e inter grupos:**  \n",
    "  Evaluar la similitud qu√≠mica dentro del grupo de activos y dentro del de inactivos, as√≠ como entre ambos grupos, es importante para entender la diversidad y la dificultad del problema.  \n",
    "  Esto ayuda a definir si el modelo podr√° generalizar o si existen subgrupos muy distintos.\n",
    "\n",
    "- **Definir un baseline:**  \n",
    "  Es fundamental establecer un modelo o m√©todo base sencillo (baseline) para comparar el desempe√±o de modelos m√°s complejos.  \n",
    "  Ejemplo: un modelo que siempre predice la clase mayoritaria o usa una m√©trica simple para referencia.\n",
    "\n",
    "## C√≥mo ayudar y colaborar en el proyecto\n",
    "\n",
    "- **Reportar issues y bugs:**  \n",
    "  Si encontr√°s errores o comportamientos inesperados, abrir un issue en GitHub con detalles claros.\n",
    "\n",
    "- **Contribuir con c√≥digo:**  \n",
    "  Crear ramas feature para nuevas funcionalidades o mejoras, y hacer Pull Requests (PR) para revisi√≥n.\n",
    "\n",
    "- **Documentar cambios:**  \n",
    "  Mantener actualizado el README, comentarios en c√≥digo y documentaci√≥n general.\n",
    "\n",
    "- **Compartir ideas y feedback:**  \n",
    "  Discutir mejoras, nuevas funcionalidades o problemas en reuniones o a trav√©s de los canales designados.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retos y Problemas Comunes en Modelado de IA para Quimioinform√°tica\n",
    "\n",
    "Adem√°s de los puntos b√°sicos, estos son algunos desaf√≠os espec√≠ficos que suelen presentarse al trabajar con datos qu√≠micos y biol√≥gicos para modelado con IA:\n",
    "\n",
    "- **Calidad y ruido en los datos:**  \n",
    "  Resultados experimentales pueden contener errores, inconsistencias o datos contradictorios, afectando la calidad del modelo.\n",
    "\n",
    "- **Representaci√≥n molecular incompleta o insuficiente:**  \n",
    "  No siempre las representaciones est√°ndar capturan toda la complejidad qu√≠mica necesaria para predecir actividad o propiedades.\n",
    "\n",
    "- **Sobrerrepresentaci√≥n de ciertas clases qu√≠micas:**  \n",
    "  Algunas familias moleculares pueden estar sobrerrepresentadas, lo que puede sesgar el modelo hacia ellas.\n",
    "\n",
    "- **Overfitting por poca diversidad qu√≠mica:**  \n",
    "  Si los datos son demasiado similares, el modelo aprende patrones poco generales y falla en predecir compuestos nuevos.\n",
    "\n",
    "- **Transferibilidad y generalizaci√≥n:**  \n",
    "  Modelos que funcionan bien en un conjunto de datos pueden no generalizar a otros targets, ensayos o condiciones.\n",
    "\n",
    "- **Interpretabilidad limitada:**  \n",
    "  Los modelos complejos pueden ser dif√≠ciles de interpretar, complicando la extracci√≥n de conocimiento qu√≠mico.\n",
    "\n",
    "- **Escasez de datos para targets poco estudiados:**  \n",
    "  Muchos blancos biol√≥gicos tienen pocos datos disponibles, limitando el entrenamiento de modelos fiables.\n",
    "\n",
    "- **Desbalance de clases:**  \n",
    "  Como mencionamos, el desbalance entre activos e inactivos afecta la evaluaci√≥n y entrenamiento.\n",
    "\n",
    "- **Problemas en la integraci√≥n de m√∫ltiples fuentes de datos:**  \n",
    "  Fusionar datos de distintas bases o tipos de ensayos puede ser complejo por diferencias en formatos, condiciones y calidad.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curso_quimioinformatica_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
